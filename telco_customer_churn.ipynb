{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3An2OtrEhHhm3s2PdeiOd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshatha7710/telco-customer-churn/blob/main/telco_customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core imports\n",
        "import os, json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# libraries\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except Exception:\n",
        "    SHAP_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    IMBLEARN_AVAILABLE = True\n",
        "except Exception:\n",
        "    IMBLEARN_AVAILABLE = False\n",
        "\n",
        "# Random state\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Create outputs folder\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# Load Dataset\n",
        "data_path = \"/content/sample_data/Telco-Customer-Churn.csv\"\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"[WARN] Dataset not found at {data_path}, creating synthetic data\")\n",
        "    from sklearn.datasets import make_classification\n",
        "    X_synthetic, y_synthetic = make_classification(\n",
        "        n_samples=2000, n_features=20, n_informative=10,\n",
        "        n_redundant=5, n_classes=2, weights=[0.69, 0.31],\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    df = pd.DataFrame(X_synthetic, columns=[f\"feature_{i}\" for i in range(20)])\n",
        "    df[\"Churn\"] = np.where(y_synthetic==1, \"Yes\", \"No\")\n",
        "else:\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"[INFO] Dataset loaded. Shape: {df.shape}\")\n",
        "\n",
        "# EDA (Task 1)\n",
        "print(\"----- EDA -----\")\n",
        "\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Show a sample that includes customerID for the report appendix, then drop ID before model prep\n",
        "print(df.head())   # this prints the sample with customerID present (if it exists)\n",
        "\n",
        "if 'customerID' in df.columns:\n",
        "    # drop before preprocessing (customerID is an identifier, not a feature)\n",
        "    df.drop(columns=['customerID'], inplace=True)\n",
        "\n",
        "# 1. Basic checks\n",
        "print(df.head())\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "print(\"\\nTarget distribution:\\n\", df[\"Churn\"].value_counts())\n",
        "\n",
        "# 2. Target distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Churn', data=df)\n",
        "plt.title('Churn Distribution BEFORE SMOTE')\n",
        "plt.savefig(\"outputs/churn_distribution_before_smote.png\")\n",
        "plt.close()\n",
        "\n",
        "# 3. Numeric features EDA\n",
        "numerical_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.histplot(df[col], bins=30, kde=True)\n",
        "    plt.title(f'{col} Histogram')\n",
        "    plt.savefig(f\"outputs/{col}_hist.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Boxplot for outlier detection\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.boxplot(x='Churn', y=col, data=df)\n",
        "    plt.title(f'{col} Boxplot by Churn')\n",
        "    plt.savefig(f\"outputs/{col}_boxplot.png\")\n",
        "    plt.close()\n",
        "\n",
        "# 4. Correlation heatmap\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(df[numerical_cols].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
        "plt.savefig(\"outputs/correlation_heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"[INFO] EDA plots saved in outputs/\")\n",
        "\n",
        "# Preprocessing (Task 2)\n",
        "def preprocess(df):\n",
        "    categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "    if \"Churn\" in categorical_cols:\n",
        "        categorical_cols.remove(\"Churn\")\n",
        "\n",
        "    numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', num_pipeline, numerical_cols),\n",
        "        ('cat', cat_pipeline, categorical_cols)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "    X = df.drop(columns=\"Churn\")\n",
        "    y = df[\"Churn\"].map({\"No\":0, \"Yes\":1})\n",
        "\n",
        "    X_trans = preprocessor.fit_transform(X)\n",
        "\n",
        "    # Handle imbalance\n",
        "    if IMBLEARN_AVAILABLE:\n",
        "        sm = SMOTE(random_state=RANDOM_STATE)\n",
        "        X_trans, y = sm.fit_resample(X_trans, y)\n",
        "\n",
        "    return X_trans, y, preprocessor, categorical_cols, numerical_cols\n",
        "\n",
        "X, y, preprocessor, cat_cols, num_cols = preprocess(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# VISUALIZE BALANCED DATA (Figure 1 - After SMOTE)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y.map({0: 'No', 1: 'Yes'}))\n",
        "plt.title('Churn Distribution AFTER SMOTE')\n",
        "plt.ylabel('Count (Balanced)')\n",
        "plt.xlabel('Churn Status')\n",
        "plt.savefig(\"outputs/churn_distribution_after_smote.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"[INFO] 'After SMOTE' distribution plot saved for Figure 1.\")\n",
        "# Models & Hyperparameter Tuning\n",
        "models = {\n",
        "    \"dummy\": DummyClassifier(strategy=\"most_frequent\"),\n",
        "    \"random_forest\": RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100),\n",
        "}\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    models[\"xgboost\"] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "\n",
        "# Tuned Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "dt_param_grid = {'max_depth':[5,10,15], 'min_samples_leaf':[5,10]}\n",
        "tuned_dt = GridSearchCV(dt_model, dt_param_grid, cv=3, scoring='f1', n_jobs=1)\n",
        "models[\"tuned_decision_tree\"] = tuned_dt\n",
        "\n",
        "# Tuned Neural Network\n",
        "nn_model = MLPClassifier(max_iter=300, random_state=RANDOM_STATE, early_stopping=True)\n",
        "nn_param_grid = {'hidden_layer_sizes':[(32,16),(64,32),(64,)], 'alpha':[0.0001,0.001]}\n",
        "tuned_nn = GridSearchCV(nn_model, nn_param_grid, cv=3, scoring='f1', n_jobs=1)\n",
        "models[\"tuned_neural_network\"] = tuned_nn\n",
        "\n",
        "# Training & Evaluation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"[INFO] Training {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    best_model = model.best_estimator_ if hasattr(model,'best_estimator_') else model\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_proba = best_model.predict_proba(X_test)[:,1] if hasattr(best_model,\"predict_proba\") else y_pred\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"roc_auc\": roc_auc_score(y_test, y_proba),\n",
        "        \"pr_auc\": average_precision_score(y_test, y_proba),\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "    if hasattr(model,'best_params_'):\n",
        "        results[name][\"best_params\"] = model.best_params_\n",
        "        print(f\"Best Parameters: {model.best_params_}\")\n",
        "\n",
        "    # Confusion matrix plot\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.savefig(f\"outputs/{name}_confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Save results\n",
        "with open(\"outputs/results.json\",\"w\") as f:\n",
        "    json.dump(results,f,indent=4)\n",
        "print(\"[INFO] Training complete. Results saved to outputs/results.json\")\n",
        "\n",
        "# ROC-AUC Curve Comparison (Figure 11)\n",
        "from sklearn.metrics import roc_curve, auc # <-- Ensure this import is present!\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Only plot the main comparison models (DT, NN, RF, XGBoost)\n",
        "    if name not in [\"dummy\"]:\n",
        "        best_model = model.best_estimator_ if hasattr(model,'best_estimator_') else model\n",
        "\n",
        "        # Check if the model has predict_proba\n",
        "        if hasattr(best_model, \"predict_proba\"):\n",
        "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{name.replace(\"_\", \" \").title()} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Baseline (AUC = 0.5)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC-AUC Curve Comparison of Models')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.savefig(\"outputs/roc_auc_comparison_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"[INFO] ROC-AUC comparison plot saved for Figure 11.\")\n",
        "\n",
        "# Feature Importance & Model Plots\n",
        "try:\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "except AttributeError:\n",
        "    feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "# Feature importance for tree models\n",
        "for name in [\"tuned_decision_tree\",\"random_forest\",\"xgboost\"]:\n",
        "    if name in models:\n",
        "        model_to_check = models[name].best_estimator_ if hasattr(models[name],'best_estimator_') else models[name]\n",
        "        if hasattr(model_to_check,\"feature_importances_\"):\n",
        "            fi = model_to_check.feature_importances_\n",
        "            sorted_idx = fi.argsort()[-20:]\n",
        "            plt.figure(figsize=(12,8))\n",
        "            plt.barh(feature_names[sorted_idx], fi[sorted_idx])\n",
        "            plt.title(f\"{name} Feature Importances\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"outputs/{name}_feature_importance.png\")\n",
        "            plt.close()\n",
        "\n",
        "# MLP loss curve\n",
        "if \"tuned_neural_network\" in models:\n",
        "    nn_model = models[\"tuned_neural_network\"].best_estimator_\n",
        "    if hasattr(nn_model,\"loss_curve_\"):\n",
        "        plt.figure(figsize=(8,5))\n",
        "        plt.plot(nn_model.loss_curve_)\n",
        "        plt.title(\"Tuned Neural Network Training Loss Curve\")\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"outputs/nn_loss_curve.png\")\n",
        "        plt.close()\n",
        "\n",
        "# SHAP Explanations (Ethics Discussion)\n",
        "if SHAP_AVAILABLE and XGBOOST_AVAILABLE:\n",
        "    print(\"[INFO] Generating SHAP explanations\")\n",
        "    xgb_model = models[\"xgboost\"].best_estimator_ if hasattr(models[\"xgboost\"],'best_estimator_') else models[\"xgboost\"]\n",
        "\n",
        "    if hasattr(xgb_model,'feature_importances_'):\n",
        "        explainer = shap.TreeExplainer(xgb_model)\n",
        "        X_sample = X_test[:200]\n",
        "        feature_names_list = feature_names.tolist()\n",
        "\n",
        "        try:\n",
        "            shap_values = explainer.shap_values(X_sample)\n",
        "            X_sample_df = pd.DataFrame(X_sample, columns=feature_names_list)\n",
        "            shap.summary_plot(shap_values, X_sample_df, show=False)\n",
        "            plt.savefig(\"outputs/shap_summary.png\")\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] SHAP plotting failed: {e}\")\n",
        "\n",
        "print(\"[INFO] All outputs saved in: outputs/\")\n",
        "print(\"[INFO] AI Ethics: SMOTE used to address class imbalance, SHAP for explainability.\")\n",
        "print(\"[INFO] Post-deployment: Monitor model drift, retrain periodically, log misclassifications for fairness analysis.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPIqjtFnVN-m",
        "outputId": "556f792e-c75a-4e00-f4c5-db4cd3d90d38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Dataset loaded. Shape: (7043, 21)\n",
            "----- EDA -----\n",
            "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
            "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
            "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
            "3  7795-CFOCW    Male              0      No         No      45           No   \n",
            "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
            "\n",
            "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
            "0  No phone service             DSL             No  ...               No   \n",
            "1                No             DSL            Yes  ...              Yes   \n",
            "2                No             DSL            Yes  ...               No   \n",
            "3  No phone service             DSL            Yes  ...              Yes   \n",
            "4                No     Fiber optic             No  ...               No   \n",
            "\n",
            "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
            "0          No          No              No  Month-to-month              Yes   \n",
            "1          No          No              No        One year               No   \n",
            "2          No          No              No  Month-to-month              Yes   \n",
            "3         Yes          No              No        One year               No   \n",
            "4          No          No              No  Month-to-month              Yes   \n",
            "\n",
            "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
            "0           Electronic check          29.85         29.85     No  \n",
            "1               Mailed check          56.95       1889.50     No  \n",
            "2               Mailed check          53.85        108.15    Yes  \n",
            "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
            "4           Electronic check          70.70        151.65    Yes  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  Female              0     Yes         No       1           No   \n",
            "1    Male              0      No         No      34          Yes   \n",
            "2    Male              0      No         No       2          Yes   \n",
            "3    Male              0      No         No      45           No   \n",
            "4  Female              0      No         No       2          Yes   \n",
            "\n",
            "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
            "0  No phone service             DSL             No          Yes   \n",
            "1                No             DSL            Yes           No   \n",
            "2                No             DSL            Yes          Yes   \n",
            "3  No phone service             DSL            Yes           No   \n",
            "4                No     Fiber optic             No           No   \n",
            "\n",
            "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
            "0               No          No          No              No  Month-to-month   \n",
            "1              Yes          No          No              No        One year   \n",
            "2               No          No          No              No  Month-to-month   \n",
            "3              Yes         Yes          No              No        One year   \n",
            "4               No          No          No              No  Month-to-month   \n",
            "\n",
            "  PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \\\n",
            "0              Yes           Electronic check           29.85         29.85   \n",
            "1               No               Mailed check           56.95       1889.50   \n",
            "2              Yes               Mailed check           53.85        108.15   \n",
            "3               No  Bank transfer (automatic)           42.30       1840.75   \n",
            "4              Yes           Electronic check           70.70        151.65   \n",
            "\n",
            "  Churn  \n",
            "0    No  \n",
            "1    No  \n",
            "2   Yes  \n",
            "3    No  \n",
            "4   Yes  \n",
            "\n",
            "Missing values:\n",
            " gender               0\n",
            "SeniorCitizen        0\n",
            "Partner              0\n",
            "Dependents           0\n",
            "tenure               0\n",
            "PhoneService         0\n",
            "MultipleLines        0\n",
            "InternetService      0\n",
            "OnlineSecurity       0\n",
            "OnlineBackup         0\n",
            "DeviceProtection     0\n",
            "TechSupport          0\n",
            "StreamingTV          0\n",
            "StreamingMovies      0\n",
            "Contract             0\n",
            "PaperlessBilling     0\n",
            "PaymentMethod        0\n",
            "MonthlyCharges       0\n",
            "TotalCharges        11\n",
            "Churn                0\n",
            "dtype: int64\n",
            "\n",
            "Target distribution:\n",
            " Churn\n",
            "No     5174\n",
            "Yes    1869\n",
            "Name: count, dtype: int64\n",
            "[INFO] EDA plots saved in outputs/\n",
            "[INFO] 'After SMOTE' distribution plot saved for Figure 1.\n",
            "[INFO] Training dummy\n",
            "[INFO] Training random_forest\n",
            "[INFO] Training xgboost\n",
            "[INFO] Training tuned_decision_tree\n",
            "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 5}\n",
            "[INFO] Training tuned_neural_network\n",
            "Best Parameters: {'alpha': 0.001, 'hidden_layer_sizes': (64, 32)}\n",
            "[INFO] Training complete. Results saved to outputs/results.json\n",
            "[INFO] ROC-AUC comparison plot saved for Figure 11.\n",
            "[INFO] Generating SHAP explanations\n",
            "[INFO] All outputs saved in: outputs/\n",
            "[INFO] AI Ethics: SMOTE used to address class imbalance, SHAP for explainability.\n",
            "[INFO] Post-deployment: Monitor model drift, retrain periodically, log misclassifications for fairness analysis.\n"
          ]
        }
      ]
    }
  ]
}